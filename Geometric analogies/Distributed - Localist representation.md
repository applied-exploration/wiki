**Distributed representation** is generally defined to have the following properties ([Hinton et al., 1986](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B47); [Plate, 2002](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B92)):

• A concept is represented by a pattern of activity over a collection of neurons (i.e., more than one neuron is required to represent a concept).

• Each neuron participates in the representation of more than one concept.



By contrast, in **localist representation**, a single neuron represents a single concept on a stand-alone basis. But that doesn’t preclude a collection of neurons representing a single concept. The critical distinction between localist units and distributed ones is that localist units have “meaning and interpretation” whereas the distributed ones don’t. Many authors have pointed out this distinction.

• [Elman (1995](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B26), p. 210): “_These representations are distributed, which typically has the consequence that interpretable information cannot be obtained by examining activity of single hidden units_.”

• [Thorpe (1995](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B124), p. 550): “_With a local representation, activity in individual units can be interpreted directly… with distributed coding individual units cannot be interpreted without knowing the state of other units in the network_.”

• [Plate (2002)](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B92):“_Another equivalent property is that in a distributed representation one cannot interpret the meaning of activity on a single neuron in isolation: the meaning of activity on any particular neuron is dependent on the activity in other neurons ([Thorpe, 1995](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B124))._”

Thus, the fundamental difference between localist and distributed representation is only in the interpretation and meaning of the units, nothing else. Therefore, any and all kinds of models can be built with either type of representation; there are no limitations as explained by [Roy (2012)](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B109).

Reviewing single cell studies, [Roy (2012)](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B109) found evidence that single cell activations can have “meaning and interpretation,” starting from the lowest levels of processing such as the retina. Thus, localist representation is definitely used in the brain. [Roy (2013)](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B110) found that multimodal invariant cells exist in the brain that can easily identify objects and concepts and such evidence supports the grandmother cell theory ([Barlow, 1995](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B5), [2009](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B4); [Gross, 2002](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B45)). This paper builds on those previous ones and provides further evidence for widespread use of localist representation by examining columnar organization of the neocortex and the evidence for category cells.

### Other Characteristics of Distributed Representation

(a) **Representational efficiency –** Distributed representation is computationally attractive because it can store multiple concepts using a small set of neurons. With _n_ binary output neurons, it can represent _2_n concepts because that many different patterns are possible with that collection of binary neurons. With localist representation, _n_ neurons can only represent _n_ concepts. In Section “Columnar Organization in the Neocortex,” I explain that this property of distributed representation could be its greatest weakness because such a representation cannot be a feasible structure for processing in the brain, given the evidence for columnar organization of the neocortex.

(b) **Mapping efficiency –** Distributed representation allows for a more compact overall structure (mapping function) from input nodes to the output ones and that means less number of connections and weights to train. Such a mapping function requires less training data and will generalize better.

(c) **Resiliency** – A distributed representation based mapping function is resilient in the sense that degradation of a few elements in the network structure may not disrupt or effect the overall performance of the structure.

(d) **Sparse distributed representation –** A distributed representation is sparse if only a small fraction of the _n_ neurons is used to represent a subset of the concepts. Some argue that representation in the brain is sparse ([Földiak, 1990](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B30); [Olshausen and Field, 1997](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B83); [Hromádka et al., 2008](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B51); [Yu et al., 2013](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full#B132)).

[Source](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00186/full)